{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGYqWU7_7B_T",
        "outputId": "bcd178f2-f5ae-4078-af4e-55e68581e022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "GOOGLE_COLAB = True\n",
        "path = \"\"\n",
        "if GOOGLE_COLAB:\n",
        "    from google.colab import drive, files\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "EEG_data_directory_path = '/content/drive/MyDrive/ML/project/EEG_Data/25-users/*.txt'\n",
        "Labels_directory_path = '/content/drive/MyDrive/ML/project/EEG_Data/labels/*.lab'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the EEG Data\n",
        "\n",
        "data_file_paths = glob.glob(EEG_data_directory_path)\n",
        "\n",
        "flattened_data = np.empty((0, 7168), dtype=float)\n",
        "\n",
        "for data_file_path in data_file_paths:\n",
        "\n",
        "    data = np.loadtxt(data_file_path)\n",
        "\n",
        "\n",
        "    flattened_row = data.flatten().reshape(1, -1)\n",
        "\n",
        "\n",
        "    flattened_data = np.concatenate((flattened_data, flattened_row), axis=0)\n",
        "\n",
        "print(\"Shape of Flattened EEG Data:\", flattened_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUNZ3s-ZNuDd",
        "outputId": "c678c75b-043e-4742-bc2f-45f6442d5158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Flattened EEG Data: (1045, 7168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Labels\n",
        "label_file_paths = glob.glob(Labels_directory_path)\n",
        "\n",
        "labels = []\n",
        "\n",
        "label_mapping = {\"disike\": 0, \"like\": 1}\n",
        "\n",
        "for label_file_path in label_file_paths:\n",
        "    with open(label_file_path, 'r') as label_file:\n",
        "        label_word = label_file.read().strip().lower()\n",
        "        label_value = label_mapping.get(label_word, None)\n",
        "        if label_value is not None:\n",
        "            labels.append(label_value)\n",
        "\n",
        "labels = np.array(labels).reshape(-1, 1)\n",
        "\n",
        "print(\"Shape of Labels:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PsWmrbpNcbQ",
        "outputId": "47c042e4-4cd3-44ad-e9bd-ec819d016a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Labels: (1045, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Combining the Flattened EEG Data with respective Labels\n",
        "combined_data = np.hstack((flattened_data, labels))\n",
        "\n",
        "print(\"Shape of Combined Data:\", combined_data.shape)\n",
        "\n",
        "# Extract features and labels from the combined data\n",
        "eeg_features, labels = combined_data[:, :-1], combined_data[:, -1]\n",
        "\n",
        "# Standardize the features (mean=0, variance=1)\n",
        "scaler = StandardScaler()\n",
        "eeg_features_standardized = scaler.fit_transform(eeg_features)\n",
        "\n",
        "# Apply Principal Component Analysis (PCA) for dimensionality reduction\n",
        "# Adjust n_components based on your requirements\n",
        "n_components = 50\n",
        "pca = PCA(n_components=n_components)\n",
        "eeg_features_pca = pca.fit_transform(eeg_features_standardized)\n",
        "\n",
        "# Combine the preprocessed features with labels\n",
        "preprocessed_data = np.hstack((eeg_features_pca, labels.reshape(-1, 1)))\n",
        "\n",
        "print(\"Shape of Preprocessed Data:\", preprocessed_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs22ltC2Nhb6",
        "outputId": "ca762df2-435f-4f71-a501-0ff5d4cee3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Combined Data: (1045, 7169)\n",
            "Shape of Preprocessed Data: (1045, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[:, :-1], preprocessed_data[:, -1], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of the logistic regression model:\", accuracy)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM6HHvepE7Q5",
        "outputId": "eac95e65-5a67-41bc-cd1b-ce32813c9a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the logistic regression model: 0.7703349282296651\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.83      0.80       114\n",
            "         1.0       0.78      0.69      0.73        95\n",
            "\n",
            "    accuracy                           0.77       209\n",
            "   macro avg       0.77      0.76      0.77       209\n",
            "weighted avg       0.77      0.77      0.77       209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'preprocessed_data' is your preprocessed and feature-extracted data\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[:, :-1], preprocessed_data[:, -1], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Train the model on the training data\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of the SVM model:\", accuracy)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXrGdxh6CUp1",
        "outputId": "3d5b1116-876c-401c-e243-e0476d3404a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the SVM model: 0.7942583732057417\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.78      0.81       114\n",
            "         1.0       0.75      0.81      0.78        95\n",
            "\n",
            "    accuracy                           0.79       209\n",
            "   macro avg       0.79      0.80      0.79       209\n",
            "weighted avg       0.80      0.79      0.79       209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Assuming 'preprocessed_data' is your preprocessed and feature-extracted data\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[:, :-1], preprocessed_data[:, -1], test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the ANN model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # For binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJKPeHYpGnTX",
        "outputId": "30071e97-02a8-4b2a-efc1-87c705a644f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "21/21 [==============================] - 1s 7ms/step - loss: 0.6434 - accuracy: 0.6632 - val_loss: 0.5973 - val_accuracy: 0.7024\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7590 - val_loss: 0.5451 - val_accuracy: 0.7202\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7889 - val_loss: 0.5023 - val_accuracy: 0.7381\n",
            "Epoch 4/10\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8099 - val_loss: 0.4723 - val_accuracy: 0.7262\n",
            "Epoch 5/10\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8383 - val_loss: 0.4518 - val_accuracy: 0.7560\n",
            "Epoch 6/10\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8653 - val_loss: 0.4326 - val_accuracy: 0.7560\n",
            "Epoch 7/10\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8922 - val_loss: 0.4140 - val_accuracy: 0.7738\n",
            "Epoch 8/10\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9072 - val_loss: 0.3982 - val_accuracy: 0.7679\n",
            "Epoch 9/10\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9266 - val_loss: 0.3916 - val_accuracy: 0.7619\n",
            "Epoch 10/10\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9476 - val_loss: 0.3795 - val_accuracy: 0.8036\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8230\n",
            "Test Accuracy: 82.30%\n",
            "7/7 [==============================] - 0s 1ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.79      0.83       114\n",
            "         1.0       0.77      0.86      0.82        95\n",
            "\n",
            "    accuracy                           0.82       209\n",
            "   macro avg       0.82      0.83      0.82       209\n",
            "weighted avg       0.83      0.82      0.82       209\n",
            "\n"
          ]
        }
      ]
    }
  ]
}